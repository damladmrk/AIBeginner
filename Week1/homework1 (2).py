# -*- coding: utf-8 -*-
"""Homework1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nnWSddUF2lbq6jhpkC0PwoPWhtSuQ3Xz
"""
# IN THIS WE COMPARE LOGISTIC REGRESSION & ANN

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
from plotly.offline import iplot, plot
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import mean_absolute_error

df = pd.read_csv("heart.csv")

df.head()

# @title Age

from matplotlib import pyplot as plt
df['Age'].plot(kind='hist', bins=20, title='Age')
plt.gca().spines[['top', 'right',]].set_visible(False)

df.describe()

df.info()

cat_cols = ['Sex', 'ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope']

binary_cols = ['Sex', 'ExerciseAngina']
le = LabelEncoder()
for col in binary_cols:
    df[col] = le.fit_transform(df[col])

df = pd.get_dummies(df, columns=['ChestPainType', 'RestingECG', 'ST_Slope'], drop_first=True)

df.info()

df = df.astype({col: 'int' for col in df.select_dtypes('bool').columns})

df.head(5)

X = df.drop('HeartDisease', axis=1)
y = df['HeartDisease']

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2)

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score

# --------------------------------
# Logistik Regression
# --------------------------------
log_model = LogisticRegression()
log_model.fit(X_train, y_train)

y_pred_log = log_model.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred_log))
print(confusion_matrix(y_test, y_pred_log))
print(classification_report(y_test, y_pred_log))

C_values = np.logspace(-3, 2, 20)
acc_scores = []

for c in C_values:
    model = LogisticRegression(C=c, solver='liblinear', penalty='l2', max_iter=300)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    acc_scores.append(accuracy_score(y_test, y_pred))

plt.figure(figsize=(8, 5))
plt.semilogx(C_values, acc_scores, marker='o', linestyle='-', color='darkgreen')
plt.xlabel('C Value')
plt.ylabel('Accuracy')
plt.title('Logistig Regression dependency on C')
plt.grid(True)
plt.tight_layout()
plt.show()
print("Most Efficent C Score: ", max(acc_scores))

# --------------------------------
# ANN
# --------------------------------
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping

ann_model = Sequential()
ann_model.add(Dense(32, input_dim=X_train.shape[1], activation='relu'))
ann_model.add(Dropout(0.2))
ann_model.add(Dense(16, activation='relu'))
ann_model.add(Dense(1, activation='sigmoid'))

ann_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

history = ann_model.fit(X_train, y_train, validation_data=(X_test, y_test),
                        epochs=100, batch_size=16, verbose=0, callbacks=[early_stop])


y_pred_ann = ann_model.predict(X_test)
y_pred_ann_class = (y_pred_ann > 0.5).astype(int)

print("=== ANN ===")
print("Accuracy:", accuracy_score(y_test, y_pred_ann_class))
print(confusion_matrix(y_test, y_pred_ann_class))
print(classification_report(y_test, y_pred_ann_class))

from sklearn.metrics import roc_curve

fpr_log, tpr_log, _ = roc_curve(y_test, log_model.predict_proba(X_test)[:, 1])
fpr_ann, tpr_ann, _ = roc_curve(y_test, y_pred_ann)

plt.figure(figsize=(8, 6))
plt.plot(fpr_log, tpr_log, label='Logistic Regression')
plt.plot(fpr_ann, tpr_ann, label='ANN')
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve Comparison')
plt.legend()
plt.grid(True)
plt.show()

